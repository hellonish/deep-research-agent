Machine learning models sometimes learn the training examples by heart instead of learning patterns that work on new data. When that happens, the model does very well on the training set but poorly on the validation set. To avoid this, you can stop training early when validation performance stops improving, or add a penalty term to the loss so that the model stays simpler. Another option is to randomly turn off some neurons during training so the model cannot rely on any single pathway.
