# Wort: Agentic Deep Research Platform

Wort is an autonomous research platform designed to execute deep, hierarchical, and comprehensive research on complex topics. It utilizes a multi-agent orchestrated workflow, combining LLM reasoning, advanced search capabilities, and vector-backed semantic memory to gather, deduplicate, and synthesize findings into highly detailed, academic-style reports.

## System Architecture

Wort operates using a structured, multi-agent hierarchy governed by an Orchestrator. The architecture is designed to handle both breadth (discovering new subtopics) and depth (deep-diving into specific questions).

### 1. The Orchestrator Agent (Level 1)
The central supervisor of the platform. The Orchestrator is responsible for managing the entire lifecycle of a research request.
- **Workflow:**
  1.  **Planning:** Passes the raw user query to the `PlannerAgent` to generate an initial set of research probes (the frontier).
  2.  **Supervisor Loop:** Iterates through the frontier. For each probe:
      - Checks the `QdrantStore` vector database to see if the semantic meaning of the probe has already been answered (Deduplication).
      - If not covered, delegates the probe to the `ResearcherAgent` for a deep dive.
      - Receives the synthesized `KnowledgeItem` back.
  3.  **Gap Analysis:** Analyzes the latest findings against the original goal to identify missing information and spawns new probes, dynamically expanding the frontier.
  4.  **Synthesis:** Once the loop concludes (or limits are hit), passes all gathered `KnowledgeItem`s to the `WriterAgent`.

### 2. The Researcher Agent (Level 2)
The specialized agent that handles the actual data gathering and synthesis for a *single* specific probe. It operates autonomously in a loop.
- **Workflow (Router → Executor → Answer):**
  1.  **Router:** An LLM analyzes the current probe, previously gathered context, and the latest tool output to decide the next action. It can choose to call a specific tool or synthesize an answer.
  2.  **Executor:** If a tool is chosen, the `ToolExecutor` runs it (e.g., searching Tavily, scraping a URL with Firecrawl, downloading a PDF, or reading an ArXiv paper).
  3.  **Synthesis (Answer):** Once the Router decides enough information is gathered (or `max_steps` is hit), the Researcher retrieves prior relevant knowledge from the vector store (RAG) and synthesizes a comprehensive resolution to the probe. This resolution is saved back to the vector store as a `Document`.

### 3. The Planner & Writer Agents
- **Planner Agent:** Categorizes the initial user request and breaks it down into a structured list of actionable research steps.
- **Writer Agent:** Takes the massive collection of `KnowledgeItem`s and structures them into a final `ResearchReport`. It forces the output into specific block types (text, table, code, chart, source_list) and enforces inline citations pointing back to the original scraped URLs.

### 4. Vector Memory (Qdrant)
Wort uses Qdrant as its semantic memory layer.
- **RAG (Retrieval-Augmented Generation):** Before synthesizing an answer, the Researcher fetches similar past findings.
- **Deduplication:** The Orchestrator computes the cosine similarity of new probes against existing findings in the database to prevent redundant API calls and repetitive research.

---

## Configuration & Tuning Parameters

Wort's behavior can be heavily customized to balance speed, cost, and report depth. These parameters are primarily controlled in `agents/config/config.py` and passed down through the agents.

### Core Cost & Depth Controls (`ReportConfig`)

These are the primary levers for tuning the platform. They can be configured via presets (`COMPACT`, `STANDARD`, `DEEP`) or manually overridden during testing.

| Parameter | Type | Location | Description |
| :--- | :--- | :--- | :--- |
| `num_plan_steps` | `int` | `ReportConfig` | The maximum number of initial research questions generated by the Planner. A higher number results in more initial breadth. |
| `max_depth` | `int` | `ReportConfig` | The absolute maximum number of loops the Orchestrator will run. This is the ultimate kill switch for the entire research process, preventing infinite gap analysis loops. |
| `max_steps` | `int` | `ReportConfig` | The maximum number of tool executions the Researcher Agent is allowed to perform for a *single* probe before it is forced to synthesize an answer. |
| `dupe_threshold` | `float` | `ReportConfig` | **Critical Tuning Parameter.** A cosine similarity score (0.0 to 1.0). When the Orchestrator evaluates a probe, if a document in the vector store matches the probe's semantic meaning with a score *higher* than this threshold, the probe is skipped ("Already Covered").<br><br>- **`0.92` (High):** Strict deduplication. Probes will only be skipped if they are nearly identical to existing findings. Results in massive, expensive, and sometimes repetitive reports.<br>- **`0.75` (Medium):** Standard. Skips probes that are semantically similar.<br>- **`0.60` (Low):** Aggressive deduplication. Will rapidly skip probes if the general topic has been touched upon, resulting in faster and cheaper, but potentially shallower, reports. |

### Component-Level Settings

**Orchestrator Level**
- `num_plan_steps` (via `PlannerAgent.create_plan`): Limits the initial breadth.
- `max_depth` (via `OrchestratorAgent.__init__`): Limits the total orchestration loops.

**Researcher Level (`agents/researcher/researcher.py`)**
- `RAG_TOP_K` (`int`, default `3`): The number of prior `KnowledgeItem`s injected into the context window before synthesizing an answer. Higher values provide more historical context but consume more tokens.
- `max_steps`: Limits the Router loop per probe.

**Vector Store Level (`agents/config/config.py`)**
- `DENSE_MODEL`: The sentence-transformer model used for semantic search (e.g., `"sentence-transformers/all-MiniLM-L6-v2"`).
- `SPARSE_MODEL`: The model used for keyword search (e.g., `"prithivida/Splade_pp_en_v1"`).

---

## Cost Calculation & Estimation

Wort leverages external APIs (LLMs, Search, Scraping). Because it acts autonomously, understanding your theoretical maximum cost is crucial. 

You can estimate your max cost footprint per run by looking at your `ReportConfig`:

### 1. LLM API Calls (e.g., Gemini / OpenAI)
- **Planner Agent:** 1 call per run (Generates the initial probes).
- **Researcher Agent (Router):** Up to `max_steps` calls *per executed probe*.
- **Researcher Agent (Answer):** 1 call *per executed probe*.
- **Orchestrator Agent (Gap Analysis):** 1 call *per executed probe* (excluding the final probe).
- **Writer Agent:** 1 massive context call at the end.
- **Maximum API Calls Formula:** `1 (Planner) + [ (max_steps + 1 + 1) * Executed_Probes ] + 1 (Writer)`

*Note: The number of `Executed_Probes` can be anywhere from 1 up to `max_depth`, heavily depending on your `dupe_threshold`. If your threshold is very low (e.g., `0.6`), probes are skipped, drastically reducing LLM calls.*

### 2. Search & Scrape API Costs
- **Search (Tavily/SerpAPI):** The agent only searches when the Router LLM decides it needs to. Theoretical max is `max_steps * Executed_Probes`.
- **Scraping (Firecrawl):** Like search, it only scrapes when explicitly directed. Scraping heavy API costs (Firecrawl charges per page) accumulate fast if `max_steps` is high and the LLM decides to scrape multiple deep links.

**Cost Control Best Practice:** Always start with `ReportConfig.COMPACT()` while iterating on your prompt, which strictly bounds API calls, before unleashing `ReportConfig.DEEP()` for final reports.

---

## HTML Viewer (`tests/viewer.html`)

The final output of the Writer Agent is a structured JSON file containing `ContentBlock`s. To convert this into a beautiful, human-readable report, Wort includes a local HTML viewer.

**Features:**
- **MathJax Integration:** Renders LaTeX and mathematical formulas (`$e=mc^2$`) automatically perfectly formatted.
- **Dynamic Blocks:** Renders markdown text, responsive data tables, syntax-highlighted code blocks (via Highlight.js), and interactive charts (via Chart.js).
- **Interactive Citations:** JavaScript logic automatically parses `[1]` format inline citations generated by the Writer Agent and converts them into clickable anchor links that scroll to the primary `source_list`.

**Usage:**
Run a local HTTP server in the directory containing the HTML file and the results JSON:
```bash
cd tests
python -m http.server 8000
```
Then navigate to `http://localhost:8000/viewer.html`.
